{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import random\n",
    "import time\n",
    "import re\n",
    "# current version of seaborn generates a bunch of warnings that we'll ignore\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to test for captcha block or IP ban\n",
    "def get_URL(position,location):\n",
    "    #from torrequest import TorRequest\n",
    "    \"\"\"[Build a template url for a dummy call to verify the site isn't returning a captcha]\n",
    "    Args:\n",
    "        position ([string]): [job for query]\n",
    "        location ([string]): [location for query]\n",
    "    Returns:\n",
    "        [string]: [formatted url]\n",
    "    \"\"\"\n",
    "    template = 'https://www.indeed.com/jobs?q={}&l={}&fromage=1&sort=date'\n",
    "                \n",
    "    position = position.replace(' ', '%20')\n",
    "    location = location.replace(' ', '+')\n",
    "    url = template.format(position,location)\n",
    "    return url\n",
    "\n",
    "\n",
    "# from torrequest import TorRequest\n",
    "# tr=TorRequest(password='your_super_secure_password')\n",
    "position = 'data scientist'\n",
    "location = 'california'\n",
    "# tr.reset_identity()\n",
    "response = requests.get(get_URL(position,location))\n",
    "# This will either return an HTML block for a captcha or of a search result\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desc_features(job_url):\n",
    "    \"\"\"Parses each job description, searching for and extracting values for features\n",
    "\n",
    "    Args:\n",
    "        job_url (string): http address of each job posting\n",
    "\n",
    "    Returns:\n",
    "        tuple: job feature values\n",
    "    \"\"\"\n",
    "    response_job_desc = requests.get(job_url)\n",
    "    soup = BeautifulSoup(response_job_desc.text, 'html.parser')\n",
    "\n",
    "    \n",
    "    try:\n",
    "        salary_and_jType = soup.find('div', id='salaryInfoAndJobType').text.strip()\n",
    "    except:\n",
    "        salary_and_jType = None\n",
    "    if salary_and_jType == None:\n",
    "        try:\n",
    "            salary_and_jType = soup.find('div',id=\"icl-u-xs-block jobsearch-ReqAndQualSection-item--title\").text.replace(\"\\n\", \"\").strip()\n",
    "        except:\n",
    "            salary_and_jType = None\n",
    "    #TODO get benefits from its designated section\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        sal_guide_items = []\n",
    "        items = soup.find('ul',class_='css-1lyr5hv eu4oa1w0')\n",
    "        for i in items:\n",
    "            sal_guide_items.append(i.text)\n",
    "    except:\n",
    "        sal_guide_items = None\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        salfromsection = soup.find('span',class_='icl-u-xs-mr--xs').text\n",
    "    except:\n",
    "        salfromsection = None\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        job_type_items = []\n",
    "        job_type_from_section = soup.find('div',class_='jobsearch-JobDescriptionSection-sectionItem').next_sibling.children\n",
    "        for i in job_type_from_section:\n",
    "            if i.text == 'Job Type':\n",
    "                continue\n",
    "            else:\n",
    "                job_type_items.append(i.text)\n",
    "    except:\n",
    "        job_type_items = None\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        requirements = soup.find(class_=\"icl-u-xs-block jobsearch-ReqAndQualSection-item--title\").text.replace(\"\\n\", \"\").strip()      \n",
    "\n",
    "    except:\n",
    "        requirements = None\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        description = soup.find(id=\"jobDescriptionText\").text.replace('\\n', '')\n",
    "    except:\n",
    "        description = None\n",
    "        \n",
    "        \n",
    "    # A nifty little workaround for evading detection.\n",
    "    time.sleep(.5+random()*3)\n",
    "    #TODO assess h2 tags commonalities to determine if these section descriptions are from Indeed or are at least of only a few variations.\n",
    "        #you could then distinguish the description into sections and conduct NLP etc each.\n",
    "    raw_desc_soup = soup\n",
    "    return salary_and_jType, sal_guide_items, salfromsection, job_type_items, requirements, description, raw_desc_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO condense these with lists, particularly fields that have .text.strip()\n",
    "def get_features(post):\n",
    "    \"\"\"parses search results and extracts basic job feature values,\n",
    "        then combines this with output of 'get_desc_features' function.\n",
    "\n",
    "    Args:\n",
    "        post (string): response for each post in search results page\n",
    "\n",
    "    Returns:\n",
    "        dict: single-feature deep dictionary of features (dictionary keys) and their values (dictionary values)\n",
    "    \"\"\"\n",
    "    datapoint_dict = {}\n",
    "\n",
    "    title = post.find('h2',\n",
    "              attrs={'class': lambda e: e.startswith('jobTitle') if e else False}).text.replace('new', '')\n",
    "\n",
    "    company = post.find('span', 'companyName').text.strip()\n",
    "    try:\n",
    "        rating = post.find('span', 'ratingNumber').text\n",
    "    except:\n",
    "        rating = None\n",
    "\n",
    "    location = post.find('div', 'companyLocation').text.strip()\n",
    "    postDate = post.find('span', 'date').text\n",
    "    extractDate = datetime.today().strftime('%Y-%m-%d')\n",
    "    summary = post.find('div', 'job-snippet').text.strip().replace('\\n', ' ')\n",
    "    url = 'https://www.indeed.com'+ post.find('a', href = re.compile(r'[/]([a-z]|[A-Z])\\w+')).attrs['href']\n",
    "\n",
    "    try:\n",
    "        estimated_salary = post.find('span','estimated-salary').text.strip()\n",
    "    except:\n",
    "        estimated_salary = None\n",
    "    try:\n",
    "        salary = post.find('div','metadata salary-snippet-container').text.strip()\n",
    "    except:\n",
    "        salary = None\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "    salary_and_jType, sal_guide_items, salfromsection, job_type_items, requirements, description, raw_desc_soup = get_desc_features(url)\n",
    "    datapoint_dict = {\n",
    "                        'title':title,\n",
    "                        'company':company,\n",
    "                        'rating':rating,\n",
    "                        'location':location,\n",
    "                        'salary':salary,\n",
    "                        'estimated_salary':estimated_salary,\n",
    "                        'postDate':postDate,\n",
    "                        'extractDate':extractDate,\n",
    "                        'summary':summary,\n",
    "                        'url':url,\n",
    "                        'salary_and_jType':salary_and_jType,\n",
    "                        'sal_guide_items':sal_guide_items,\n",
    "                        'salfromsection':salfromsection,\n",
    "                        'job_type_items':job_type_items,\n",
    "                        'requirements':requirements,\n",
    "                        'description':description,\n",
    "                        'raw_desc_soup':raw_desc_soup}\n",
    "    if len(datapoint_dict) > 0:\n",
    "        return datapoint_dict\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(position, location):\n",
    "    \"\"\"[Conducts the web scraping process]\n",
    "    Args:\n",
    "        position ([string]): [job position for indeed.com query]\n",
    "        position ([string]): [job location for indeed.com query]\n",
    "        \n",
    "        Returns:\n",
    "        [csv]: [scraped data]\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    # extract the job data\n",
    "    while True:\n",
    "        response = requests.get(get_URL(position, location))\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        searchResults = soup.find('div', id='mosaic-provider-jobcards')\n",
    "        refinedsearchResults = searchResults.find_all('div', attrs={'class': lambda e: e.startswith('cardOutline') if e else False})\n",
    "        \n",
    "\n",
    "        raw_posts = []\n",
    "        for post in refinedsearchResults:\n",
    "            raw_posts.append(post)\n",
    "        \n",
    "        n = 0\n",
    "        for post in raw_posts:\n",
    "            datapoint = get_features(post)\n",
    "            data = data.append(datapoint, ignore_index=True)\n",
    "        # Again, a nifty little workaround for evading detection.\n",
    "            n+=1\n",
    "            print(n)\n",
    "            \n",
    "        try:\n",
    "            url = 'https://www.indeed.com' + soup.find('a', {'aria-label': 'Next'}).get('href')\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    name = position.replace(' ','_')\n",
    "    loc = location.replace(' ','_')\n",
    "    day = date.today()\n",
    "    # save the job data\n",
    "    data.to_csv(f'../app/data/scraped_{name}_{loc}.csv', index=False)\n",
    "    return raw_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pennsylvania\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-8118fb1d40cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlocation\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-5d8aa1f92808>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(position, location)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0msearchResults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mosaic-provider-jobcards'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mrefinedsearchResults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearchResults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cardOutline'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "#state_names = [ \"alabama\", \"arkansas\",  \"arizona\",  \"colorado\", \"connecticut\", \"delaware\",  \"georgia\", \"iowa\", \"idaho\", \"illinois\", \"indiana\", \"kansas\", \"kentucky\", \"louisiana\", \"massachusetts\", \"maryland\", \"maine\", \"michigan\", \"minnesota\", \"missouri\", \"mississippi\", \"montana\", \"north carolina\", \"north dakota\", \"nebraska\", \"new hampshire\", \"new jersey\", \"new mexico\", \"nevada\",  \"ohio\", \"oklahoma\", \"oregon\", \"pennsylvania\", \"rhode island\", \"south carolina\", \"south dakota\", \"tennessee\", \"utah\", \"virginia\",  \"vermont\",  \"wisconsin\", \"west virginia\", \"wyoming\"]\n",
    "\n",
    "\n",
    "state_names = [ \"pennsylvania\", \"rhode island\", \"south carolina\", \"south dakota\", \"tennessee\", \"utah\", \"virginia\",  \"vermont\",  \"wisconsin\", \"west virginia\", \"wyoming\"]\n",
    "\n",
    "for state in state_names:\n",
    "    position = 'data scientist'\n",
    "    location = state\n",
    "    print(state)\n",
    "    data = main(position,location )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 'data scientist'\n",
    "location = 'california'\n",
    "main(position,location )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 'data scientist'\n",
    "location = 'remote'\n",
    "main(position,location )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 'data scientist'\n",
    "location = 'new york'\n",
    "main(position,location )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 'data scientist'\n",
    "location = 'texas'\n",
    "main(position,location )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 'data scientist'\n",
    "location = 'washington'\n",
    "main(position,location )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-83d63d2207f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mposition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data scientist'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'florida'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlocation\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-5d8aa1f92808>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(position, location)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0msearchResults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mosaic-provider-jobcards'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mrefinedsearchResults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearchResults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cardOutline'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "position = 'data scientist'\n",
    "location = 'florida'\n",
    "main(position,location )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 'data scientist'\n",
    "location = 'massachusetts'\n",
    "main(position,location )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 'data scientist'\n",
    "location = 'oregon'\n",
    "main(position,location )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  below is used for various adjustments to my webscraping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>extractDate</th>\n",
       "      <th>job_type_items</th>\n",
       "      <th>location</th>\n",
       "      <th>postDate</th>\n",
       "      <th>rating</th>\n",
       "      <th>raw_desc_soup</th>\n",
       "      <th>requirements</th>\n",
       "      <th>sal_guide_items</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_and_jType</th>\n",
       "      <th>salfromsection</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recruiting From Scratch</td>\n",
       "      <td>Who is Recruiting from Scratch: Recruiting fro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Remote in Portland, OR 97035</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>5+ years experience in data engineering or dat...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=0921a823554b3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fisher Investments</td>\n",
       "      <td>Are you highly analytical and looking for an o...</td>\n",
       "      <td>Estimated $56.7K - $71.9K a year</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Portland, OR 97204+1 location</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>3.5</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['', 'Not provided by employer', \"$56.7K - $71...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Be a part of our data modernization efforts th...</td>\n",
       "      <td>Data Science Associate</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   company                                        description  \\\n",
       "0  Recruiting From Scratch  Who is Recruiting from Scratch: Recruiting fro...   \n",
       "1       Fisher Investments  Are you highly analytical and looking for an o...   \n",
       "\n",
       "                   estimated_salary extractDate  job_type_items  \\\n",
       "0                               NaN  2022-06-21             NaN   \n",
       "1  Estimated $56.7K - $71.9K a year  2022-06-21             NaN   \n",
       "\n",
       "                        location     postDate  rating  \\\n",
       "0   Remote in Portland, OR 97035  PostedToday     NaN   \n",
       "1  Portland, OR 97204+1 location  PostedToday     3.5   \n",
       "\n",
       "                                       raw_desc_soup  requirements  \\\n",
       "0  <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...           NaN   \n",
       "1  <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...           NaN   \n",
       "\n",
       "                                     sal_guide_items  \\\n",
       "0                                                NaN   \n",
       "1  ['', 'Not provided by employer', \"$56.7K - $71...   \n",
       "\n",
       "                       salary            salary_and_jType  \\\n",
       "0  $160,000 - $200,000 a year  $160,000 - $200,000 a year   \n",
       "1                         NaN                         NaN   \n",
       "\n",
       "               salfromsection  \\\n",
       "0  $160,000 - $200,000 a year   \n",
       "1                         NaN   \n",
       "\n",
       "                                             summary                   title  \\\n",
       "0  5+ years experience in data engineering or dat...          Data Scientist   \n",
       "1  Be a part of our data modernization efforts th...  Data Science Associate   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.indeed.com/rc/clk?jk=0921a823554b3...  \n",
       "1  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'../app/data/scraped_data_scientist_oregon.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating Old Data With New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alabama has 7 records\n",
      "arkansas has 1 records\n",
      "arizona has 10 records\n",
      "colorado has 10 records\n",
      "connecticut has 30 records\n",
      "delaware has 7 records\n",
      "georgia has 45 records\n",
      "iowa has 3 records\n",
      "idaho has 1 records\n",
      "illinois has 30 records\n",
      "indiana has 10 records\n",
      "kansas has 6 records\n",
      "kentucky has 2 records\n",
      "louisiana has 5 records\n",
      "massachusetts has 210 records\n",
      "maryland has 12 records\n",
      "maine has 1 records\n",
      "michigan has 7 records\n",
      "minnesota has 9 records\n",
      "missouri has 3 records\n",
      "mississippi has 1 records\n",
      "montana has 1 records\n",
      "north_carolina has 13 records\n",
      "north_dakota has 1 records\n",
      "nebraska has 1 records\n",
      "new_hampshire has 1 records\n",
      "new_jersey has 15 records\n",
      "new_mexico has 1 records\n",
      "nevada has 1 records\n",
      "ohio has 10 records\n",
      "oklahoma has 1 records\n",
      "oregon has 2 records\n",
      "457\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>extractDate</th>\n",
       "      <th>job_type_items</th>\n",
       "      <th>location</th>\n",
       "      <th>postDate</th>\n",
       "      <th>rating</th>\n",
       "      <th>raw_desc_soup</th>\n",
       "      <th>requirements</th>\n",
       "      <th>sal_guide_items</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_and_jType</th>\n",
       "      <th>salfromsection</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recruiting From Scratch</td>\n",
       "      <td>Who is Recruiting from Scratch: Recruiting fro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Remote in Huntsville, AL</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>5+ years experience in data engineering or dat...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=977d1ccb6d1a1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Food Management Search</td>\n",
       "      <td>SR Financial Data Analyst- Fully remote - ANY ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Remote in United States</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lead various allocation data analysis projects...</td>\n",
       "      <td>SR Financial Data Analyst- Fully remote</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gregor Diagnostics</td>\n",
       "      <td>Role: Senior Data ScientistAbout Gregor Diagno...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Remote in United States</td>\n",
       "      <td>PostedPosted 1 day ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Senior Data Scientist will work closely la...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SynergisticIT</td>\n",
       "      <td>At SynergisticIT, we aim to bring aboard IT ...</td>\n",
       "      <td>Estimated $77.7K - $98.3K a year</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>PostedPosted 1 day ago</td>\n",
       "      <td>4.2</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['', 'Not provided by employer', \"$77.7K - $98...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time, Contract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Collaborate with dynamic teams of engineers, d...</td>\n",
       "      <td>Entry Level Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=57d47b0524890...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9Rooftops</td>\n",
       "      <td>WE ARE HIRING IN MULTIPLE LOCATIONS ACROSS THE...</td>\n",
       "      <td>Estimated $109K - $138K a year</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Birmingham, AL 35242</td>\n",
       "      <td>PostedPosted 1 day ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['', 'Not provided by employer', \"$109K - $138...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O Communication skills to ask questions of cli...</td>\n",
       "      <td>Statistician/Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=e23726e90096e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Sanofi</td>\n",
       "      <td>Overview At Sanofi Large Molecule Research Pla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cambridge, MA 02238 (Mid-Cambridge area)+1 loc...</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>4.1</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Track record of applying machine learning/ dee...</td>\n",
       "      <td>Principal Data Scientist Machine Learning for ...</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>PAREXEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As a Statistical Programmer you will support v...</td>\n",
       "      <td>Statistical Programmer I (Poland)</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>NATIONAL GRID CO USA (NE POWER)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Waltham, MA 02454</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>3.7</td>\n",
       "      <td>&lt;html lang=\"en\"&gt;\\n&lt;head&gt;\\n&lt;title&gt;hCaptcha solv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employ sophisticated analytics, machine learni...</td>\n",
       "      <td>Lead Data Scientist, Data Science</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>PAREXEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Senior Statistical Programmer provides tec...</td>\n",
       "      <td>Senior Statistical Programmer FSP (Poland)</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>Recruiting From Scratch</td>\n",
       "      <td>Who is Recruiting from Scratch: Recruiting fro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Remote in Boston, MA 02109+3 locations</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>5+ years experience in data engineering or dat...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=89b4714ca9540...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>834 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             company  \\\n",
       "0            Recruiting From Scratch   \n",
       "1             Food Management Search   \n",
       "2                 Gregor Diagnostics   \n",
       "3                      SynergisticIT   \n",
       "4                          9Rooftops   \n",
       "..                               ...   \n",
       "372                           Sanofi   \n",
       "373                          PAREXEL   \n",
       "374  NATIONAL GRID CO USA (NE POWER)   \n",
       "375                          PAREXEL   \n",
       "376          Recruiting From Scratch   \n",
       "\n",
       "                                           description  \\\n",
       "0    Who is Recruiting from Scratch: Recruiting fro...   \n",
       "1    SR Financial Data Analyst- Fully remote - ANY ...   \n",
       "2    Role: Senior Data ScientistAbout Gregor Diagno...   \n",
       "3      At SynergisticIT, we aim to bring aboard IT ...   \n",
       "4    WE ARE HIRING IN MULTIPLE LOCATIONS ACROSS THE...   \n",
       "..                                                 ...   \n",
       "372  Overview At Sanofi Large Molecule Research Pla...   \n",
       "373                                                NaN   \n",
       "374                                                NaN   \n",
       "375                                                NaN   \n",
       "376  Who is Recruiting from Scratch: Recruiting fro...   \n",
       "\n",
       "                     estimated_salary extractDate job_type_items  \\\n",
       "0                                 NaN  2022-06-21            NaN   \n",
       "1                                 NaN  2022-06-21            NaN   \n",
       "2                                 NaN  2022-06-21            NaN   \n",
       "3    Estimated $77.7K - $98.3K a year  2022-06-21            NaN   \n",
       "4      Estimated $109K - $138K a year  2022-06-21            NaN   \n",
       "..                                ...         ...            ...   \n",
       "372                               NaN  2022-06-21            NaN   \n",
       "373                               NaN  2022-06-21            NaN   \n",
       "374                               NaN  2022-06-21            NaN   \n",
       "375                               NaN  2022-06-21            NaN   \n",
       "376                               NaN  2022-06-21            NaN   \n",
       "\n",
       "                                              location  \\\n",
       "0                             Remote in Huntsville, AL   \n",
       "1                              Remote in United States   \n",
       "2                              Remote in United States   \n",
       "3                                              Alabama   \n",
       "4                                 Birmingham, AL 35242   \n",
       "..                                                 ...   \n",
       "372  Cambridge, MA 02238 (Mid-Cambridge area)+1 loc...   \n",
       "373                                      Massachusetts   \n",
       "374                                  Waltham, MA 02454   \n",
       "375                                      Massachusetts   \n",
       "376             Remote in Boston, MA 02109+3 locations   \n",
       "\n",
       "                   postDate  rating  \\\n",
       "0               PostedToday     NaN   \n",
       "1               PostedToday     NaN   \n",
       "2    PostedPosted 1 day ago     NaN   \n",
       "3    PostedPosted 1 day ago     4.2   \n",
       "4    PostedPosted 1 day ago     NaN   \n",
       "..                      ...     ...   \n",
       "372             PostedToday     4.1   \n",
       "373             PostedToday     3.6   \n",
       "374             PostedToday     3.7   \n",
       "375             PostedToday     3.6   \n",
       "376             PostedToday     NaN   \n",
       "\n",
       "                                         raw_desc_soup requirements  \\\n",
       "0    <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...          NaN   \n",
       "1    <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...          NaN   \n",
       "2    <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...          NaN   \n",
       "3    <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...          NaN   \n",
       "4    <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...          NaN   \n",
       "..                                                 ...          ...   \n",
       "372  <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...          NaN   \n",
       "373                                                NaN          NaN   \n",
       "374  <html lang=\"en\">\\n<head>\\n<title>hCaptcha solv...          NaN   \n",
       "375                                                NaN          NaN   \n",
       "376  <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...          NaN   \n",
       "\n",
       "                                       sal_guide_items  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3    ['', 'Not provided by employer', \"$77.7K - $98...   \n",
       "4    ['', 'Not provided by employer', \"$109K - $138...   \n",
       "..                                                 ...   \n",
       "372                                                NaN   \n",
       "373                                                NaN   \n",
       "374                                                NaN   \n",
       "375                                                NaN   \n",
       "376                                                NaN   \n",
       "\n",
       "                         salary            salary_and_jType  \\\n",
       "0    $160,000 - $200,000 a year  $160,000 - $200,000 a year   \n",
       "1                           NaN                         NaN   \n",
       "2                           NaN                   Full-time   \n",
       "3                           NaN         Full-time, Contract   \n",
       "4                           NaN                         NaN   \n",
       "..                          ...                         ...   \n",
       "372                         NaN                         NaN   \n",
       "373                         NaN                         NaN   \n",
       "374                         NaN                         NaN   \n",
       "375                         NaN                         NaN   \n",
       "376  $160,000 - $200,000 a year  $160,000 - $200,000 a year   \n",
       "\n",
       "                 salfromsection  \\\n",
       "0    $160,000 - $200,000 a year   \n",
       "1                           NaN   \n",
       "2                           NaN   \n",
       "3                           NaN   \n",
       "4                           NaN   \n",
       "..                          ...   \n",
       "372                         NaN   \n",
       "373                         NaN   \n",
       "374                         NaN   \n",
       "375                         NaN   \n",
       "376  $160,000 - $200,000 a year   \n",
       "\n",
       "                                               summary  \\\n",
       "0    5+ years experience in data engineering or dat...   \n",
       "1    Lead various allocation data analysis projects...   \n",
       "2    The Senior Data Scientist will work closely la...   \n",
       "3    Collaborate with dynamic teams of engineers, d...   \n",
       "4    O Communication skills to ask questions of cli...   \n",
       "..                                                 ...   \n",
       "372  Track record of applying machine learning/ dee...   \n",
       "373  As a Statistical Programmer you will support v...   \n",
       "374  Employ sophisticated analytics, machine learni...   \n",
       "375  The Senior Statistical Programmer provides tec...   \n",
       "376  5+ years experience in data engineering or dat...   \n",
       "\n",
       "                                                 title  \\\n",
       "0                                       Data Scientist   \n",
       "1              SR Financial Data Analyst- Fully remote   \n",
       "2                                Senior Data Scientist   \n",
       "3                           Entry Level Data Scientist   \n",
       "4                          Statistician/Data Scientist   \n",
       "..                                                 ...   \n",
       "372  Principal Data Scientist Machine Learning for ...   \n",
       "373                  Statistical Programmer I (Poland)   \n",
       "374                  Lead Data Scientist, Data Science   \n",
       "375         Senior Statistical Programmer FSP (Poland)   \n",
       "376                                     Data Scientist   \n",
       "\n",
       "                                                   url  \n",
       "0    https://www.indeed.com/rc/clk?jk=977d1ccb6d1a1...  \n",
       "1    https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "2    https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "3    https://www.indeed.com/rc/clk?jk=57d47b0524890...  \n",
       "4    https://www.indeed.com/rc/clk?jk=e23726e90096e...  \n",
       "..                                                 ...  \n",
       "372  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "373  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "374  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "375  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "376  https://www.indeed.com/rc/clk?jk=89b4714ca9540...  \n",
       "\n",
       "[834 rows x 17 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_names = [ \"alabama\", \"arkansas\",  \"arizona\", \"california\", \"colorado\", \"connecticut\", \"delaware\", \"florida\", \"georgia\", \"remote\", \"iowa\", \"idaho\", \"illinois\", \"indiana\", \"kansas\", \"kentucky\", \"louisiana\", \"massachusetts\", \"maryland\", \"maine\", \"michigan\", \"minnesota\", \"missouri\", \"mississippi\", \"montana\", \"north carolina\", \"north dakota\", \"nebraska\", \"new hampshire\", \"new jersey\", \"new mexico\", \"nevada\", \"new york\", \"ohio\", \"oklahoma\", \"oregon\", \"pennsylvania\", \"rhode island\", \"south carolina\", \"south dakota\", \"tennessee\", \"texas\", \"utah\", \"virginia\",  \"vermont\", \"washington\", \"wisconsin\", \"west virginia\", \"wyoming\"]\n",
    "\n",
    "lst = []\n",
    "records = 0\n",
    "for i in state_names:\n",
    "    i = i.replace(' ','_')\n",
    "    try:\n",
    "        location = pd.read_csv(f'../app/data/scraped_data_scientist_{i}.csv')\n",
    "        print(f'{i} has {len(location)} records')\n",
    "        records += len(location)\n",
    "        lst.append(location)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(records)\n",
    "\n",
    "todays_scrape = pd.concat(lst)\n",
    "## unblock if you miss too many days\n",
    "#total = todays_scrape.to_csv('../app/data/total.csv', index= False)\n",
    "\n",
    "total = pd.read_csv(f'../app/data/total.csv')\n",
    "\n",
    "lst.append(total)\n",
    "\n",
    "total = pd.concat(lst)\n",
    "total.to_csv('../app/data/total.csv', index= False)\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below are bits of code I employ if something goes wrong with the webscraping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#fix old imports\n",
    "\n",
    "data['extractDate']= pd.to_datetime(data['extractDate'])\n",
    "\n",
    "def pDate(row):\n",
    "    from datetime import datetime, date, timedelta\n",
    "\n",
    "    #days_ago = row['dateposted']\n",
    "    delta = timedelta(0)\n",
    "    try:\n",
    "        return row['extractDate'] - delta\n",
    "    except:\n",
    "        return row\n",
    "\n",
    "data['extractDate'] = data.apply( lambda row : pDate(row), axis = 1)\n",
    "data['extractDate'] = data['extractDate'].astype(str)\n",
    "#data.to_csv('../app/data/scraped_data_scientist_remote_2022-04-14.csv', index= False)\n",
    "data.extractDate.unique()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# codescraps in case they change the html and break my parsers\n",
    "\n",
    "searchResults = soup.find('div', id='mosaic-provider-jobcards')\n",
    "refinedsearchResults = searchResults.find_all('div', attrs={'class': lambda e: e.startswith('cardOutline') if e else False})\n",
    "len(refinedsearchResults)\n",
    "z = searchResults.children\n",
    "lst = []\n",
    "for i in z:\n",
    "    lst.append(i)\n",
    "\n",
    "x = lst[0]\n",
    "\n",
    "#checking again\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#searchResults = soup.find('div', id='mosaic-provider-jobcards')\n",
    "refinedsearchResults = soup.find_all('div', attrs={'class': lambda e: e.startswith('cardOutline') if e else False})\n",
    "        \n",
    "\n",
    "raw_posts = []\n",
    "for post in refinedsearchResults:\n",
    "        raw_posts.append(post)\n",
    "        n = 0\n",
    "\n",
    "z = raw_posts[0]\n",
    "url = z.find('a', href=True)\n",
    "url\n",
    "\n",
    "\n",
    "z.find('a', href = re.compile(r'[/]([a-z]|[A-Z])\\w+')).attrs['href']\n",
    "z\n",
    "\n",
    "postDate = z.find('span', 'date').text\n",
    "extractDate = datetime.today().strftime('%Y-%m-%d')\n",
    "summary = z.find('div', 'job-snippet').text.strip().replace('\\n', ' ')\n",
    "\n",
    "summary\n",
    "\n",
    "company_name = z.find('a', attrs={'class':'turnstileLink companyOverviewLink'}).text.strip()\n",
    "company_name\n",
    "\n",
    "job_title = z.find('a', attrs={'class':'jcs-JobTitle'}).text.strip()\n",
    "job_title\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac83f05b37eb5c5c49ba67e50f0047ddfbc4b30205fc79ee5f327b9c0ac37f55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "46216370387cf43888a1dc9433c5a4546bda9feed2ad4f35c2a851da9960dc54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
