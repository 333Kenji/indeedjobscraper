{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import random\n",
    "import time\n",
    "import re\n",
    "# current version of seaborn generates a bunch of warnings that we'll ignore\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this to test for captcha block or IP ban\n",
    "def get_URL(position,location):\n",
    "    #from torrequest import TorRequest\n",
    "    \"\"\"[Build a template url for a dummy call to verify the site isn't returning a captcha]\n",
    "    Args:\n",
    "        position ([string]): [job for query]\n",
    "        location ([string]): [location for query]\n",
    "    Returns:\n",
    "        [string]: [formatted url]\n",
    "    \"\"\"\n",
    "    template = 'https://www.indeed.com/jobs?q={}&l={}&fromage=1&sort=date'\n",
    "                \n",
    "    position = position.replace(' ', '%20')\n",
    "    location = location.replace(' ', '+')\n",
    "    url = template.format(position,location)\n",
    "    return url\n",
    "\n",
    "\n",
    "# from torrequest import TorRequest\n",
    "# tr=TorRequest(password='your_super_secure_password')\n",
    "position = 'data scientist'\n",
    "location = 'california'\n",
    "# tr.reset_identity()\n",
    "response = requests.get(get_URL(position,location))\n",
    "# This will either return an HTML block for a captcha or of a search result\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desc_features(job_url):\n",
    "    \"\"\"Parses each job description, searching for and extracting values for features\n",
    "\n",
    "    Args:\n",
    "        job_url (string): http address of each job posting\n",
    "\n",
    "    Returns:\n",
    "        tuple: job feature values\n",
    "    \"\"\"\n",
    "    response_job_desc = requests.get(job_url)\n",
    "    soup = BeautifulSoup(response_job_desc.text, 'html.parser')\n",
    "\n",
    "    \n",
    "    try:\n",
    "        salary_and_jType = soup.find('div', id='salaryInfoAndJobType').text.strip()\n",
    "    except:\n",
    "        salary_and_jType = None\n",
    "    if salary_and_jType == None:\n",
    "        try:\n",
    "            salary_and_jType = soup.find('div',id=\"icl-u-xs-block jobsearch-ReqAndQualSection-item--title\").text.replace(\"\\n\", \"\").strip()\n",
    "        except:\n",
    "            salary_and_jType = None\n",
    "    #TODO get benefits from its designated section\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        sal_guide_items = []\n",
    "        items = soup.find('ul',class_='css-1lyr5hv eu4oa1w0')\n",
    "        for i in items:\n",
    "            sal_guide_items.append(i.text)\n",
    "    except:\n",
    "        sal_guide_items = None\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        salfromsection = soup.find('span',class_='icl-u-xs-mr--xs').text\n",
    "    except:\n",
    "        salfromsection = None\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        job_type_items = []\n",
    "        job_type_from_section = soup.find('div',class_='jobsearch-JobDescriptionSection-sectionItem').next_sibling.children\n",
    "        for i in job_type_from_section:\n",
    "            if i.text == 'Job Type':\n",
    "                continue\n",
    "            else:\n",
    "                job_type_items.append(i.text)\n",
    "    except:\n",
    "        job_type_items = None\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        requirements = soup.find(class_=\"icl-u-xs-block jobsearch-ReqAndQualSection-item--title\").text.replace(\"\\n\", \"\").strip()      \n",
    "\n",
    "    except:\n",
    "        requirements = None\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        description = soup.find(id=\"jobDescriptionText\").text.replace('\\n', '')\n",
    "    except:\n",
    "        description = None\n",
    "        \n",
    "        \n",
    "    # A nifty little workaround for evading detection.\n",
    "    time.sleep(.5+random()*3)\n",
    "    #TODO assess h2 tags commonalities to determine if these section descriptions are from Indeed or are at least of only a few variations.\n",
    "        #you could then distinguish the description into sections and conduct NLP etc each.\n",
    "    raw_desc_soup = soup\n",
    "    return salary_and_jType, sal_guide_items, salfromsection, job_type_items, requirements, description, raw_desc_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO condense these with lists, particularly fields that have .text.strip()\n",
    "def get_features(post):\n",
    "    \"\"\"parses search results and extracts basic job feature values,\n",
    "        then combines this with output of 'get_desc_features' function.\n",
    "\n",
    "    Args:\n",
    "        post (string): response for each post in search results page\n",
    "\n",
    "    Returns:\n",
    "        dict: single-feature deep dictionary of features (dictionary keys) and their values (dictionary values)\n",
    "    \"\"\"\n",
    "    datapoint_dict = {}\n",
    "\n",
    "    title = post.find('h2',\n",
    "              attrs={'class': lambda e: e.startswith('jobTitle') if e else False}).text.replace('new', '')\n",
    "\n",
    "    company = post.find('span', 'companyName').text.strip()\n",
    "    try:\n",
    "        rating = post.find('span', 'ratingNumber').text\n",
    "    except:\n",
    "        rating = None\n",
    "\n",
    "    location = post.find('div', 'companyLocation').text.strip()\n",
    "    postDate = post.find('span', 'date').text\n",
    "    extractDate = datetime.today().strftime('%Y-%m-%d')\n",
    "    summary = post.find('div', 'job-snippet').text.strip().replace('\\n', ' ')\n",
    "    url = 'https://www.indeed.com'+ post.find('a', href = re.compile(r'[/]([a-z]|[A-Z])\\w+')).attrs['href']\n",
    "\n",
    "    try:\n",
    "        estimated_salary = post.find('span','estimated-salary').text.strip()\n",
    "    except:\n",
    "        estimated_salary = None\n",
    "    try:\n",
    "        salary = post.find('div','metadata salary-snippet-container').text.strip()\n",
    "    except:\n",
    "        salary = None\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "    salary_and_jType, sal_guide_items, salfromsection, job_type_items, requirements, description, raw_desc_soup = get_desc_features(url)\n",
    "    datapoint_dict = {\n",
    "                        'title':title,\n",
    "                        'company':company,\n",
    "                        'rating':rating,\n",
    "                        'location':location,\n",
    "                        'salary':salary,\n",
    "                        'estimated_salary':estimated_salary,\n",
    "                        'postDate':postDate,\n",
    "                        'extractDate':extractDate,\n",
    "                        'summary':summary,\n",
    "                        'url':url,\n",
    "                        'salary_and_jType':salary_and_jType,\n",
    "                        'sal_guide_items':sal_guide_items,\n",
    "                        'salfromsection':salfromsection,\n",
    "                        'job_type_items':job_type_items,\n",
    "                        'requirements':requirements,\n",
    "                        'description':description,\n",
    "                        'raw_desc_soup':raw_desc_soup}\n",
    "    if len(datapoint_dict) > 0:\n",
    "        return datapoint_dict\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(position, location):\n",
    "    \"\"\"[Conducts the web scraping process]\n",
    "    Args:\n",
    "        position ([string]): [job position for indeed.com query]\n",
    "        position ([string]): [job location for indeed.com query]\n",
    "        \n",
    "        Returns:\n",
    "        [csv]: [scraped data]\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    # extract the job data\n",
    "    while True:\n",
    "        response = requests.get(get_URL(position, location))\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        searchResults = soup.find('div', id='mosaic-provider-jobcards')\n",
    "        refinedsearchResults = searchResults.find_all('div', attrs={'class': lambda e: e.startswith('cardOutline') if e else False})\n",
    "        \n",
    "\n",
    "        raw_posts = []\n",
    "        for post in refinedsearchResults:\n",
    "            raw_posts.append(post)\n",
    "        \n",
    "        n = 0\n",
    "        for post in raw_posts:\n",
    "            datapoint = get_features(post)\n",
    "            data = data.append(datapoint, ignore_index=True)\n",
    "        # Again, a nifty little workaround for evading detection.\n",
    "            n+=1\n",
    "            print(n)\n",
    "            \n",
    "        try:\n",
    "            url = 'https://www.indeed.com' + soup.find('a', {'aria-label': 'Next'}).get('href')\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    name = position.replace(' ','_')\n",
    "    loc = location.replace(' ','_')\n",
    "    day = date.today()\n",
    "    # save the job data\n",
    "    data.to_csv(f'../app/data/scraped_{name}_{loc}.csv', index=False)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "south dakota\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-18d87297e121>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlocation\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-16877b019e3b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(position, location)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0msearchResults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mosaic-provider-jobcards'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mrefinedsearchResults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearchResults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cardOutline'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "#state_names = [ \"alabama\", \"arkansas\",  \"arizona\",  \"colorado\", \"connecticut\", \"delaware\",  \"georgia\", \"iowa\", \"idaho\", \"illinois\", \"indiana\", \"kansas\", \"kentucky\", \"louisiana\", \"massachusetts\", \"maryland\", \"maine\", \"michigan\", \"minnesota\", \"missouri\", \"mississippi\", \"montana\", \"north carolina\", \"north dakota\", \"nebraska\", \"new hampshire\", \"new jersey\", \"new mexico\", \"nevada\",  \"ohio\", \"oklahoma\", \"oregon\", \"pennsylvania\", \"rhode island\", \"south carolina\", \"south dakota\", \"tennessee\", \"utah\", \"virginia\",  \"vermont\",  \"wisconsin\", \"west virginia\", \"wyoming\"]\n",
    "\n",
    "#state_names = [ \"alabama\", \"arkansas\",  \"arizona\",  \"colorado\", \"connecticut\", \"delaware\",  \"georgia\", \"iowa\", \"idaho\", \"illinois\", \"indiana\", \"kansas\", \"kentucky\", \"louisiana\", \"massachusetts\", \"maryland\", \"maine\", \"michigan\", \"minnesota\", \"missouri\", \"mississippi\", \"montana\", \"north carolina\", \"north dakota\", \"nebraska\", \"new hampshire\", \"new jersey\", \"new mexico\", \"nevada\",  \"ohio\", \"oklahoma\", \"oregon\"]\n",
    "state_names = [\"south dakota\", \"tennessee\", \"utah\", \"virginia\",  \"vermont\",  \"wisconsin\", \"west virginia\", \"wyoming\"]\n",
    "\n",
    "for state in state_names:\n",
    "    position = 'data scientist'\n",
    "    location = state\n",
    "    print(state)\n",
    "    data = main(position,location )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 'data scientist'\n",
    "location = 'california'\n",
    "main(position,location )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 'data scientist'\n",
    "location = 'remote'\n",
    "main(position,location )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 'data scientist'\n",
    "location = 'new york'\n",
    "main(position,location )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 'data scientist'\n",
    "location = 'texas'\n",
    "main(position,location )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 'data scientist'\n",
    "location = 'washington'\n",
    "main(position,location )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 'data scientist'\n",
    "location = 'florida'\n",
    "main(position,location )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 'data scientist'\n",
    "location = 'massachusetts'\n",
    "main(position,location )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 'data scientist'\n",
    "location = 'oregon'\n",
    "main(position,location )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  below is used for various adjustments to my webscraping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>extractDate</th>\n",
       "      <th>job_type_items</th>\n",
       "      <th>location</th>\n",
       "      <th>postDate</th>\n",
       "      <th>rating</th>\n",
       "      <th>raw_desc_soup</th>\n",
       "      <th>requirements</th>\n",
       "      <th>sal_guide_items</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_and_jType</th>\n",
       "      <th>salfromsection</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fisher Investments</td>\n",
       "      <td>Are you highly analytical and looking for an o...</td>\n",
       "      <td>Estimated $56.7K - $71.9K a year</td>\n",
       "      <td>2022-06-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Portland, OR 97204+1 location</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>3.5</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['', 'Not provided by employer', \"$56.7K - $71...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Be a part of our data modernization efforts th...</td>\n",
       "      <td>Data Science Associate</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recruiting From Scratch</td>\n",
       "      <td>Who is Recruiting from Scratch: Recruiting fro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Remote in Portland, OR 97035</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>5+ years experience in data engineering or dat...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=0921a823554b3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   company                                        description  \\\n",
       "0       Fisher Investments  Are you highly analytical and looking for an o...   \n",
       "1  Recruiting From Scratch  Who is Recruiting from Scratch: Recruiting fro...   \n",
       "\n",
       "                   estimated_salary extractDate  job_type_items  \\\n",
       "0  Estimated $56.7K - $71.9K a year  2022-06-22             NaN   \n",
       "1                               NaN  2022-06-22             NaN   \n",
       "\n",
       "                        location     postDate  rating  \\\n",
       "0  Portland, OR 97204+1 location  PostedToday     3.5   \n",
       "1   Remote in Portland, OR 97035  PostedToday     NaN   \n",
       "\n",
       "                                       raw_desc_soup  requirements  \\\n",
       "0  <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...           NaN   \n",
       "1  <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...           NaN   \n",
       "\n",
       "                                     sal_guide_items  \\\n",
       "0  ['', 'Not provided by employer', \"$56.7K - $71...   \n",
       "1                                                NaN   \n",
       "\n",
       "                       salary            salary_and_jType  \\\n",
       "0                         NaN                         NaN   \n",
       "1  $160,000 - $200,000 a year  $160,000 - $200,000 a year   \n",
       "\n",
       "               salfromsection  \\\n",
       "0                         NaN   \n",
       "1  $160,000 - $200,000 a year   \n",
       "\n",
       "                                             summary                   title  \\\n",
       "0  Be a part of our data modernization efforts th...  Data Science Associate   \n",
       "1  5+ years experience in data engineering or dat...          Data Scientist   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "1  https://www.indeed.com/rc/clk?jk=0921a823554b3...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'../app/data/scraped_data_scientist_oregon.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating Old Data With New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped  7 new records for alabama\n",
      "Scraped  1 new records for arkansas\n",
      "Scraped  10 new records for arizona\n",
      "Scraped  60 new records for california\n",
      "Scraped  10 new records for colorado\n",
      "Scraped  30 new records for connecticut\n",
      "Scraped  7 new records for delaware\n",
      "Scraped  15 new records for florida\n",
      "Scraped  45 new records for georgia\n",
      "Scraped  15 new records for remote\n",
      "Scraped  3 new records for iowa\n",
      "Scraped  1 new records for idaho\n",
      "Scraped  30 new records for illinois\n",
      "Scraped  10 new records for indiana\n",
      "Scraped  6 new records for kansas\n",
      "Scraped  2 new records for kentucky\n",
      "Scraped  5 new records for louisiana\n",
      "Scraped  120 new records for massachusetts\n",
      "Scraped  12 new records for maryland\n",
      "Scraped  1 new records for maine\n",
      "Scraped  7 new records for michigan\n",
      "Scraped  9 new records for minnesota\n",
      "Scraped  3 new records for missouri\n",
      "Scraped  1 new records for mississippi\n",
      "Scraped  1 new records for montana\n",
      "Scraped  13 new records for north_carolina\n",
      "Scraped  1 new records for north_dakota\n",
      "Scraped  1 new records for nebraska\n",
      "Scraped  1 new records for new_hampshire\n",
      "Scraped  15 new records for new_jersey\n",
      "Scraped  1 new records for new_mexico\n",
      "Scraped  1 new records for nevada\n",
      "Scraped  150 new records for new_york\n",
      "Scraped  10 new records for ohio\n",
      "Scraped  1 new records for oklahoma\n",
      "Scraped  2 new records for oregon\n",
      "Scraped  120 new records for pennsylvania\n",
      "Scraped  4 new records for rhode_island\n",
      "Scraped  7 new records for south_carolina\n",
      "Scraped  1 new records for south_dakota\n",
      "Scraped  11 new records for tennessee\n",
      "Scraped  75 new records for texas\n",
      "Scraped  5 new records for utah\n",
      "Scraped  15 new records for virginia\n",
      "Scraped  3 new records for vermont\n",
      "Scraped  45 new records for washington\n",
      "Scraped  3 new records for wisconsin\n",
      "Scraped  1 new records for west_virginia\n",
      "Scraped  1 new records for wyoming\n",
      "New Records: 898\n",
      "Total Records: 1159\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>extractDate</th>\n",
       "      <th>job_type_items</th>\n",
       "      <th>location</th>\n",
       "      <th>postDate</th>\n",
       "      <th>rating</th>\n",
       "      <th>raw_desc_soup</th>\n",
       "      <th>requirements</th>\n",
       "      <th>sal_guide_items</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_and_jType</th>\n",
       "      <th>salfromsection</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recruiting From Scratch</td>\n",
       "      <td>Who is Recruiting from Scratch: Recruiting fro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Remote in Huntsville, AL</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>5+ years experience in data engineering or dat...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=977d1ccb6d1a1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Food Management Search</td>\n",
       "      <td>SR Financial Data Analyst- Fully remote - ANY ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Remote in United States</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lead various allocation data analysis projects...</td>\n",
       "      <td>SR Financial Data Analyst- Fully remote</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gregor Diagnostics</td>\n",
       "      <td>Role: Senior Data ScientistAbout Gregor Diagno...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Remote in United States</td>\n",
       "      <td>PostedPosted 1 day ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Senior Data Scientist will work closely la...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SynergisticIT</td>\n",
       "      <td>At SynergisticIT, we aim to bring aboard IT ...</td>\n",
       "      <td>Estimated $77.7K - $98.3K a year</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>PostedPosted 1 day ago</td>\n",
       "      <td>4.2</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['', 'Not provided by employer', \"$77.7K - $98...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time, Contract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Collaborate with dynamic teams of engineers, d...</td>\n",
       "      <td>Entry Level Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=57d47b0524890...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9Rooftops</td>\n",
       "      <td>WE ARE HIRING IN MULTIPLE LOCATIONS ACROSS THE...</td>\n",
       "      <td>Estimated $109K - $138K a year</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Birmingham, AL 35242</td>\n",
       "      <td>PostedPosted 1 day ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['', 'Not provided by employer', \"$109K - $138...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O Communication skills to ask questions of cli...</td>\n",
       "      <td>Statistician/Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=e23726e90096e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>NATIONAL GRID CO USA (NE POWER)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Waltham, MA 02454</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>3.7</td>\n",
       "      <td>&lt;html lang=\"en\"&gt;\\n&lt;head&gt;\\n&lt;title&gt;hCaptcha solv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employ sophisticated analytics, machine learni...</td>\n",
       "      <td>Lead Data Scientist, Data Science</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>PAREXEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Senior Statistical Programmer provides tec...</td>\n",
       "      <td>Senior Statistical Programmer FSP (Poland)</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>Recruiting From Scratch</td>\n",
       "      <td>Who is Recruiting from Scratch: Recruiting fro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Remote in Boston, MA 02109+3 locations</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>5+ years experience in data engineering or dat...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=89b4714ca9540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3067</th>\n",
       "      <td>Recruiting From Scratch</td>\n",
       "      <td>Who is Recruiting from Scratch: Recruiting fro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Remote in Portland, OR 97035</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>$160,000 - $200,000 a year</td>\n",
       "      <td>5+ years experience in data engineering or dat...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=0921a823554b3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3068</th>\n",
       "      <td>Fisher Investments</td>\n",
       "      <td>Are you highly analytical and looking for an o...</td>\n",
       "      <td>Estimated $56.7K - $71.9K a year</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Portland, OR 97204+1 location</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>3.5</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['', 'Not provided by employer', \"$56.7K - $71...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Be a part of our data modernization efforts th...</td>\n",
       "      <td>Data Science Associate</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1159 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              company  \\\n",
       "0             Recruiting From Scratch   \n",
       "1              Food Management Search   \n",
       "2                  Gregor Diagnostics   \n",
       "3                       SynergisticIT   \n",
       "4                           9Rooftops   \n",
       "...                               ...   \n",
       "2986  NATIONAL GRID CO USA (NE POWER)   \n",
       "2987                          PAREXEL   \n",
       "2988          Recruiting From Scratch   \n",
       "3067          Recruiting From Scratch   \n",
       "3068               Fisher Investments   \n",
       "\n",
       "                                            description  \\\n",
       "0     Who is Recruiting from Scratch: Recruiting fro...   \n",
       "1     SR Financial Data Analyst- Fully remote - ANY ...   \n",
       "2     Role: Senior Data ScientistAbout Gregor Diagno...   \n",
       "3       At SynergisticIT, we aim to bring aboard IT ...   \n",
       "4     WE ARE HIRING IN MULTIPLE LOCATIONS ACROSS THE...   \n",
       "...                                                 ...   \n",
       "2986                                                NaN   \n",
       "2987                                                NaN   \n",
       "2988  Who is Recruiting from Scratch: Recruiting fro...   \n",
       "3067  Who is Recruiting from Scratch: Recruiting fro...   \n",
       "3068  Are you highly analytical and looking for an o...   \n",
       "\n",
       "                      estimated_salary extractDate job_type_items  \\\n",
       "0                                  NaN  2022-06-21            NaN   \n",
       "1                                  NaN  2022-06-21            NaN   \n",
       "2                                  NaN  2022-06-21            NaN   \n",
       "3     Estimated $77.7K - $98.3K a year  2022-06-21            NaN   \n",
       "4       Estimated $109K - $138K a year  2022-06-21            NaN   \n",
       "...                                ...         ...            ...   \n",
       "2986                               NaN  2022-06-21            NaN   \n",
       "2987                               NaN  2022-06-21            NaN   \n",
       "2988                               NaN  2022-06-21            NaN   \n",
       "3067                               NaN  2022-06-21            NaN   \n",
       "3068  Estimated $56.7K - $71.9K a year  2022-06-21            NaN   \n",
       "\n",
       "                                    location                postDate  rating  \\\n",
       "0                   Remote in Huntsville, AL             PostedToday     NaN   \n",
       "1                    Remote in United States             PostedToday     NaN   \n",
       "2                    Remote in United States  PostedPosted 1 day ago     NaN   \n",
       "3                                    Alabama  PostedPosted 1 day ago     4.2   \n",
       "4                       Birmingham, AL 35242  PostedPosted 1 day ago     NaN   \n",
       "...                                      ...                     ...     ...   \n",
       "2986                       Waltham, MA 02454             PostedToday     3.7   \n",
       "2987                           Massachusetts             PostedToday     3.6   \n",
       "2988  Remote in Boston, MA 02109+3 locations             PostedToday     NaN   \n",
       "3067            Remote in Portland, OR 97035             PostedToday     NaN   \n",
       "3068           Portland, OR 97204+1 location             PostedToday     3.5   \n",
       "\n",
       "                                          raw_desc_soup requirements  \\\n",
       "0     <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...          NaN   \n",
       "1     <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...          NaN   \n",
       "2     <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...          NaN   \n",
       "3     <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...          NaN   \n",
       "4     <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...          NaN   \n",
       "...                                                 ...          ...   \n",
       "2986  <html lang=\"en\">\\n<head>\\n<title>hCaptcha solv...          NaN   \n",
       "2987                                                NaN          NaN   \n",
       "2988  <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...          NaN   \n",
       "3067  <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...          NaN   \n",
       "3068  <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...          NaN   \n",
       "\n",
       "                                        sal_guide_items  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3     ['', 'Not provided by employer', \"$77.7K - $98...   \n",
       "4     ['', 'Not provided by employer', \"$109K - $138...   \n",
       "...                                                 ...   \n",
       "2986                                                NaN   \n",
       "2987                                                NaN   \n",
       "2988                                                NaN   \n",
       "3067                                                NaN   \n",
       "3068  ['', 'Not provided by employer', \"$56.7K - $71...   \n",
       "\n",
       "                          salary            salary_and_jType  \\\n",
       "0     $160,000 - $200,000 a year  $160,000 - $200,000 a year   \n",
       "1                            NaN                         NaN   \n",
       "2                            NaN                   Full-time   \n",
       "3                            NaN         Full-time, Contract   \n",
       "4                            NaN                         NaN   \n",
       "...                          ...                         ...   \n",
       "2986                         NaN                         NaN   \n",
       "2987                         NaN                         NaN   \n",
       "2988  $160,000 - $200,000 a year  $160,000 - $200,000 a year   \n",
       "3067  $160,000 - $200,000 a year  $160,000 - $200,000 a year   \n",
       "3068                         NaN                         NaN   \n",
       "\n",
       "                  salfromsection  \\\n",
       "0     $160,000 - $200,000 a year   \n",
       "1                            NaN   \n",
       "2                            NaN   \n",
       "3                            NaN   \n",
       "4                            NaN   \n",
       "...                          ...   \n",
       "2986                         NaN   \n",
       "2987                         NaN   \n",
       "2988  $160,000 - $200,000 a year   \n",
       "3067  $160,000 - $200,000 a year   \n",
       "3068                         NaN   \n",
       "\n",
       "                                                summary  \\\n",
       "0     5+ years experience in data engineering or dat...   \n",
       "1     Lead various allocation data analysis projects...   \n",
       "2     The Senior Data Scientist will work closely la...   \n",
       "3     Collaborate with dynamic teams of engineers, d...   \n",
       "4     O Communication skills to ask questions of cli...   \n",
       "...                                                 ...   \n",
       "2986  Employ sophisticated analytics, machine learni...   \n",
       "2987  The Senior Statistical Programmer provides tec...   \n",
       "2988  5+ years experience in data engineering or dat...   \n",
       "3067  5+ years experience in data engineering or dat...   \n",
       "3068  Be a part of our data modernization efforts th...   \n",
       "\n",
       "                                           title  \\\n",
       "0                                 Data Scientist   \n",
       "1        SR Financial Data Analyst- Fully remote   \n",
       "2                          Senior Data Scientist   \n",
       "3                     Entry Level Data Scientist   \n",
       "4                    Statistician/Data Scientist   \n",
       "...                                          ...   \n",
       "2986           Lead Data Scientist, Data Science   \n",
       "2987  Senior Statistical Programmer FSP (Poland)   \n",
       "2988                              Data Scientist   \n",
       "3067                              Data Scientist   \n",
       "3068                      Data Science Associate   \n",
       "\n",
       "                                                    url  \n",
       "0     https://www.indeed.com/rc/clk?jk=977d1ccb6d1a1...  \n",
       "1     https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "2     https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "3     https://www.indeed.com/rc/clk?jk=57d47b0524890...  \n",
       "4     https://www.indeed.com/rc/clk?jk=e23726e90096e...  \n",
       "...                                                 ...  \n",
       "2986  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "2987  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "2988  https://www.indeed.com/rc/clk?jk=89b4714ca9540...  \n",
       "3067  https://www.indeed.com/rc/clk?jk=0921a823554b3...  \n",
       "3068  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "\n",
       "[1159 rows x 17 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_names = [ \"alabama\", \"arkansas\",  \"arizona\", \"california\", \"colorado\", \"connecticut\", \"delaware\", \"florida\", \"georgia\", \"remote\", \"iowa\", \"idaho\", \"illinois\", \"indiana\", \"kansas\", \"kentucky\", \"louisiana\", \"massachusetts\", \"maryland\", \"maine\", \"michigan\", \"minnesota\", \"missouri\", \"mississippi\", \"montana\", \"north carolina\", \"north dakota\", \"nebraska\", \"new hampshire\", \"new jersey\", \"new mexico\", \"nevada\", \"new york\", \"ohio\", \"oklahoma\", \"oregon\", \"pennsylvania\", \"rhode island\", \"south carolina\", \"south dakota\", \"tennessee\", \"texas\", \"utah\", \"virginia\",  \"vermont\", \"washington\", \"wisconsin\", \"west virginia\", \"wyoming\"]\n",
    "\n",
    "lst = []\n",
    "records = 0\n",
    "for i in state_names:\n",
    "    i = i.replace(' ','_')\n",
    "    try:\n",
    "        location = pd.read_csv(f'../app/data/scraped_data_scientist_{i}.csv')\n",
    "        records += len(location)\n",
    "        lst.append(location)\n",
    "        print(f'Scraped  {len(location)} new records for {i}')\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f'Scraped Records: {(records)}')\n",
    "\n",
    "todays_scrape = pd.concat(lst)\n",
    "## unblock if you miss too many days\n",
    "#total = todays_scrape.to_csv('../app/data/total.csv', index= False)\n",
    "\n",
    "total = pd.read_csv(f'../app/data/total.csv')\n",
    "lst.append(total)\n",
    "\n",
    "total = pd.concat(lst)\n",
    "\n",
    "total.drop_duplicates(inplace=True)\n",
    "\n",
    "total.to_csv('../app/data/total.csv', index= False)\n",
    "print(f'Total Records: {(len(total))}')\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chicago, IL           12\n",
       "United States         11\n",
       "Indiana                6\n",
       "Massachusetts          6\n",
       "Phoenix, AZ            6\n",
       "Cincinnati, OH         5\n",
       "Salt Lake City, UT     3\n",
       "Virginia               3\n",
       "Waltham, MA 02454      3\n",
       "Name: location, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO explain why this is being shown. remove from data and save, but also show what portion of the data it represents. Relatively miniscule.\n",
    "total[total.description.isna()].location.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below are bits of code I employ if something goes wrong with the webscraping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#fix old imports\\n\\ndata['extractDate']= pd.to_datetime(data['extractDate'])\\n\\ndef pDate(row):\\n    from datetime import datetime, date, timedelta\\n\\n    #days_ago = row['dateposted']\\n    delta = timedelta(0)\\n    try:\\n        return row['extractDate'] - delta\\n    except:\\n        return row\\n\\ndata['extractDate'] = data.apply( lambda row : pDate(row), axis = 1)\\ndata['extractDate'] = data['extractDate'].astype(str)\\n#data.to_csv('../app/data/scraped_data_scientist_remote_2022-04-14.csv', index= False)\\ndata.extractDate.unique()\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#fix old imports\n",
    "\n",
    "data['extractDate']= pd.to_datetime(data['extractDate'])\n",
    "\n",
    "def pDate(row):\n",
    "    from datetime import datetime, date, timedelta\n",
    "\n",
    "    #days_ago = row['dateposted']\n",
    "    delta = timedelta(0)\n",
    "    try:\n",
    "        return row['extractDate'] - delta\n",
    "    except:\n",
    "        return row\n",
    "\n",
    "data['extractDate'] = data.apply( lambda row : pDate(row), axis = 1)\n",
    "data['extractDate'] = data['extractDate'].astype(str)\n",
    "#data.to_csv('../app/data/scraped_data_scientist_remote_2022-04-14.csv', index= False)\n",
    "data.extractDate.unique()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# codescraps in case they change the html and break my parsers\n",
    "\n",
    "searchResults = soup.find('div', id='mosaic-provider-jobcards')\n",
    "refinedsearchResults = searchResults.find_all('div', attrs={'class': lambda e: e.startswith('cardOutline') if e else False})\n",
    "len(refinedsearchResults)\n",
    "z = searchResults.children\n",
    "lst = []\n",
    "for i in z:\n",
    "    lst.append(i)\n",
    "\n",
    "x = lst[0]\n",
    "\n",
    "#checking again\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#searchResults = soup.find('div', id='mosaic-provider-jobcards')\n",
    "refinedsearchResults = soup.find_all('div', attrs={'class': lambda e: e.startswith('cardOutline') if e else False})\n",
    "        \n",
    "\n",
    "raw_posts = []\n",
    "for post in refinedsearchResults:\n",
    "        raw_posts.append(post)\n",
    "        n = 0\n",
    "\n",
    "z = raw_posts[0]\n",
    "url = z.find('a', href=True)\n",
    "url\n",
    "\n",
    "\n",
    "z.find('a', href = re.compile(r'[/]([a-z]|[A-Z])\\w+')).attrs['href']\n",
    "z\n",
    "\n",
    "postDate = z.find('span', 'date').text\n",
    "extractDate = datetime.today().strftime('%Y-%m-%d')\n",
    "summary = z.find('div', 'job-snippet').text.strip().replace('\\n', ' ')\n",
    "\n",
    "summary\n",
    "\n",
    "company_name = z.find('a', attrs={'class':'turnstileLink companyOverviewLink'}).text.strip()\n",
    "company_name\n",
    "\n",
    "job_title = z.find('a', attrs={'class':'jcs-JobTitle'}).text.strip()\n",
    "job_title\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac83f05b37eb5c5c49ba67e50f0047ddfbc4b30205fc79ee5f327b9c0ac37f55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "46216370387cf43888a1dc9433c5a4546bda9feed2ad4f35c2a851da9960dc54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
